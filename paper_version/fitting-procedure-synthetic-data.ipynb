{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import scipy as scp\n",
    "from ribbonv2 import *\n",
    "from samplingv4 import *\n",
    "from plotResult_v2 import *\n",
    "import numpy as np\n",
    "import sklearn.metrics \n",
    "import pickle\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt[ms] for r = 10\n",
      "dt[ms] for stim = 1\n",
      "info: Stim and vesicle release of one cell, 4 recordings per stim, binned sum for r but raw for stim (dt=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "load data\n",
    "needed to take original stimulus\n",
    "\"\"\"\n",
    "\n",
    "filename = '../data/cell1.hdf5'\n",
    "f = h5py.File(filename, 'r')\n",
    "\n",
    "for item in f.attrs:\n",
    "    print(item, f.attrs[item])\n",
    "    \n",
    "stim_binary = f['stim_binary'][:]\n",
    "stim_gauss = f['stim_gauss'][:]\n",
    "\n",
    "#r_binary = f['r_binary'][:]\n",
    "#r_gauss = f['r_gauss'][:]\n",
    "\n",
    "f.close()\n",
    "\n",
    "\n",
    "# choose data\n",
    "light = stim_binary\n",
    "#data = r_binary\n",
    "\n",
    "\n",
    "# stim time with time resolution of dt =1ms\n",
    "stimT = np.arange(0, len(light),1)/1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### produce data summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "specify summary stats\n",
    "\n",
    "for n>1\n",
    "\"\"\"\n",
    "\n",
    "#data=data[1:]\n",
    "\n",
    "nSS = 9\n",
    "\n",
    "\n",
    "## specify kernel to compare traces\n",
    "g = scipy.signal.gaussian(10,2)\n",
    "\n",
    "  \n",
    "############################\n",
    "\n",
    "\"\"\"\n",
    "Pre run to get \"true\" data which we want to fit\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "## define the gaussian kernel for the comparison of the traces\n",
    "g = scipy.signal.gaussian(10,2) # (total width of kernel,std) # in 10*ms\n",
    "\n",
    "# Define true parameters\n",
    "trueK = 30#20\n",
    "trueX0 = 0.8 #1.5#2#1.5\n",
    "trueDockP = .1#05#.3\n",
    "trueRibbonLambda = .4#.4\n",
    "dockMax = 7\n",
    "ribbonMax = 50\n",
    "truerho = 0.3\n",
    "truescale = 1 #0.5\n",
    "\n",
    "params = [trueK,trueX0,trueDockP,trueRibbonLambda,dockMax,ribbonMax, truerho, truescale]\n",
    "\n",
    "celltype = -1\n",
    "light_ca_kernel =  - celltype * cone_kernel_scale(truescale)\n",
    "stimCon = scp.signal.convolve(light, light_ca_kernel, mode=\"full\")[:len(light)]  # /(1/dtstim *10)\n",
    "# resample and normalize\n",
    "dtstim = 0.001 # in ms\n",
    "Ca_raw = resampleCon(stimCon, dtstim)\n",
    "# normalize stim\n",
    "stim = (Ca_raw - np.min(Ca_raw)) / np.max(np.abs(Ca_raw - np.min(Ca_raw)))\n",
    "\n",
    "Ca = stim\n",
    "\n",
    "## Compute 'True' Traces\n",
    "nTrue = 4\n",
    "data1 = runOne(params[:-1], Ca, correlated=True) #r_binary[0] # \n",
    "data = np.zeros((nTrue,len(data1)))\n",
    "\n",
    "for i in range(0,nTrue):\n",
    "    rel = runOne(params,  Ca, correlated=True) # r_binary[i] #\n",
    "    data[i,:] = rel\n",
    "###############################################\n",
    "\n",
    "\n",
    "\n",
    "# number of recorded traces\n",
    "nTrue = len(data)\n",
    "\n",
    "lenData = len(data[0])\n",
    "trueG = np.zeros((nTrue,lenData+len(g)-1))\n",
    "\n",
    "for i in range(nTrue):\n",
    "    trueG[i,:] = scipy.signal.convolve(data[i],g)\n",
    "  \n",
    "\n",
    "# specify weights for summary stats\n",
    "unweighted_data_SS = makeSS(data,g,trueG, w = np.ones(nSS))\n",
    "# normalizing factor\n",
    "w_norm = 1/unweighted_data_SS\n",
    "w_norm[np.isinf(w_norm)] = 1/48 #(1/48 mean value for the recorded traces)\n",
    "#scaling factor for each sums stat\n",
    "w_scale =  np.ones(len(unweighted_data_SS))\n",
    "w_scale[0] = 1 # conv\n",
    "w_scale[1] = 5 # sum of all\n",
    "w_scale[2] = 5 # 1-fold\n",
    "w_scale[3] = 5 # 2-fold\n",
    "w_scale[4] = 2 # 4-fold\n",
    "w_scale[5] = 2 # 5 fold\n",
    "w_scale[6] = 4 # 6 fold\n",
    "w_scale[7] = 1 # std\n",
    "\n",
    "# final w \n",
    "w = w_norm * w_scale\n",
    "\n",
    "dataSS = makeSS(data,g,trueG,w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fitting here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### true parameters\n",
    "trueK = 25#20\n",
    "trueX0 = 0.8 #0.8 #1.5#2#1.5\n",
    "trueDockP = .2#.3\n",
    "trueRibbonLambda = .1#.4\n",
    "dockMax = 8\n",
    "ribbonMax = 50\n",
    "truerho = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "specify priors here!!!\n",
    "also: dock and ribbon size\n",
    "\"\"\"\n",
    "\n",
    "dockMax = 7\n",
    "ribbonMax = 50\n",
    "\n",
    "def makeHypersPrior():\n",
    "    \"\"\"\n",
    "    :return: hyper parameters for the ribbon prior distributions\n",
    "    \"\"\"\n",
    "    k_x0Hypers = [np.array([10, 0.5]), np.eye(2) * np.array([400, 0.1]), 4, 4]  # [mu0s,Lambda0, kappa0, nu0]\n",
    "    dPHypers = [0.3, 0.05, 3, 3]  # [mu0, sigma0sq, kappa0, nu0]\n",
    "    rlHypers = [2, 0.4]  # [k, scale(theta)] # mean=k*theta\n",
    "    rhoHypers = [0.5, 0.05, 3, 3]  # [mu0, sigma0sq, kappa0, nu0]\n",
    "    \n",
    "    kernelscaleHypers = [1.2, 0.2, 3, 3]  # [mu0, sigma0sq, kappa0, nu0]\n",
    "\n",
    "    \n",
    "    hypers = [k_x0Hypers, dPHypers, rlHypers, rhoHypers, kernelscaleHypers]\n",
    "    return hypers\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify stimulus\n",
    "\n",
    "def run_parallel_ribbon(*parameters):\n",
    "    sampsParams = np.array(parameters)\n",
    "    outUn =  runManyRibbon(light, g,trueG,dataSS, sampsParams, batchsize, w, stim_kind='light')\n",
    "    return outUn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tic time: 2019-05-16 16:02:34.592026\n",
      "\n",
      "run 0\n",
      "finished sampling, now run simulations...\n",
      "paramsmean = [19.42439349  0.77893946  0.19340494  0.37665935  7.         50.\n",
      "  0.37199328  1.03415171]\n",
      "updated hypers [[array([16.73170963,  0.69924247]), array([[1.41991161e+03, 7.33267727e+00],\n",
      "       [7.33267727e+00, 3.37069769e-01]]), 14, 14], [0.21800379800536065, 0.020114711696004074, 13, 13], [5.766593531746782, 0.08], [0.4015332920107538, 0.023397261300326145, 13, 13], [1.0724243914043465, 0.08082717935846853, 13, 13]]\n",
      "Total used time: 0:42:14.816183\n",
      "\n",
      "run 1\n",
      "finished sampling, now run simulations...\n",
      "paramsmean = [18.32950817  0.79542985  0.15386216  0.39748622  7.         50.\n",
      "  0.35083518  1.03489003]\n",
      "updated hypers [[array([17.39745903,  0.73932055]), array([[1.49523835e+03, 8.40732917e+00],\n",
      "       [8.40732917e+00, 3.97502558e-01]]), 24, 24], [0.19011613078817127, 0.014109900673819115, 23, 23], [9.741455723448528, 0.044444444444444446], [0.3794906337453572, 0.02024892932217145, 23, 23], [1.0561051030690947, 0.04939359924575484, 23, 23]]\n",
      "Total used time: 1:05:33.329145\n",
      "\n",
      "run 2\n",
      "finished sampling, now run simulations...\n",
      "paramsmean = [19.00272037  0.79027392  0.1840748   0.39492654  7.         50.\n",
      "  0.37586944  1.02861795]\n",
      "updated hypers [[array([17.86959472,  0.75430683]), array([[1.75664784e+03, 8.81459763e+00],\n",
      "       [8.81459763e+00, 4.18275809e-01]]), 34, 34], [0.18828542376155422, 0.010255735082978208, 33, 33], [13.690721089218044, 0.03076923076923077], [0.37839330319034997, 0.015473857416680904, 33, 33], [1.04777566304034, 0.03609628035937286, 33, 33]]\n",
      "Total used time: 1:29:00.722110\n",
      "\n",
      "run 3\n",
      "finished sampling, now run simulations...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## number of samples\n",
    "# if nr is to small error araises from taking best 1000 values etc.\n",
    "nSamps0 = 40000\n",
    "nSampsLate = 20000\n",
    "nsave = 1000\n",
    "\n",
    "# number of sample to update from\n",
    "nupdate0 = 10 # 20\n",
    "nupdate_late = 10 # 20\n",
    "importance_factor0 = 1#0.2\n",
    "importance_factor_late = 1#0.2\n",
    "\n",
    "\n",
    "batchsize = 4\n",
    "\n",
    "\"\"\"\n",
    "switching fitting\n",
    "\"\"\"\n",
    "\n",
    "# choose nr of processes working in parallel\n",
    "pr = 35\n",
    "\n",
    "# number of runs\n",
    "runs = 100\n",
    "\n",
    "\n",
    "# arrays for saving results \n",
    "# best nsave are saved\n",
    "outRSave = np.zeros((runs,9,nsave))\n",
    "hypersSave = []#np.zeros((runs,5,2))\n",
    "\n",
    "\n",
    "# prior parameters for ribbon params\n",
    "cHyper = [0,0,0,0,1,1,0,0] # 1 if constant, 0 else\n",
    "c2 = [0,0,0,0,dockMax,ribbonMax,0,0]\n",
    "constants = np.stack((cHyper,c2))  \n",
    "\n",
    "#hypers = hypers_old[-1]\n",
    "hypers = makeHypersPrior() # not used for uniform priors\n",
    "hypersSave.append(hypers)\n",
    "\n",
    "for noRun in range(0,runs):\n",
    "    if noRun ==0:\n",
    "        nSamps = nSamps0\n",
    "        nupdate = nupdate0\n",
    "        importance_factor = importance_factor0\n",
    "    else:\n",
    "        nSamps = nSampsLate\n",
    "        nupdate = nupdate_late\n",
    "        importance_factor = importance_factor_late\n",
    "    print()\n",
    "    print('run',noRun)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    run for params\n",
    "    \"\"\"\n",
    "\n",
    "    # sample params \n",
    "    sampsStackR = list([])\n",
    "\n",
    "\n",
    "    for j in range(0,pr):\n",
    "        sampsStackR.append(drawSamps(constants,hypers,int(nSamps/pr)))\n",
    "    \n",
    "    print('finished sampling, now run simulations...')\n",
    "\n",
    "    with multiprocessing.Pool(processes=pr) as pool:\n",
    "        outUnStackR = pool.starmap(run_parallel_ribbon, sampsStackR)\n",
    "\n",
    "    #temp3 = datetime.datetime.now()\n",
    "    #tempdiff = temp3 - temp2\n",
    "    #print('time used for ribbon fitting',tempdiff)\n",
    "\n",
    "\n",
    "    #reshape and sort results\n",
    "    outUnStackR = np.array(outUnStackR)\n",
    "    outUnR = np.zeros((9,np.shape(outUnStackR)[0]*np.shape(outUnStackR)[2]))\n",
    "    #outUn = np.zeros((6,np.shape(outUnStack)[0]*np.shape(outUnStack)[2]))\n",
    "\n",
    "    for i in range(0, np.shape(outUnStackR)[0]):\n",
    "        outUnR[:,i*np.shape(outUnStackR)[2]:i*np.shape(outUnStackR)[2]+np.shape(outUnStackR)[2]] = outUnStackR[i,:,:]\n",
    "\n",
    "    # sorting:\n",
    "    outR = outUnR[:,outUnR[-1,:].argsort()]\n",
    "\n",
    "    # update parameters\n",
    "    # using mean of best threshold samples \n",
    "    threshold = nupdate \n",
    "    params = np.mean(outR[:-1,:threshold], axis=1)\n",
    "    print('paramsmean =',params)\n",
    "    \n",
    "    #pairPlotStuff_truevalues(outR[0,:100],outR[1,:100],outR[3,:100],outR[2,:100], trueK,\n",
    "     #                   trueX0, trueRibbonLambda,trueDockP, markersize=30)\n",
    "    \n",
    "    \"\"\"\n",
    "    Prior updating for params\n",
    "    \"\"\"\n",
    "    # for params\n",
    "    hypers = makeHypers(hypers, outR, nupdate_raw=nupdate, importance_factor=importance_factor) \n",
    "    \n",
    "    print('updated hypers', hypers)\n",
    "    timer.toc()\n",
    "    \n",
    "    \n",
    "    hypersSave.append(hypers)\n",
    "    outRSave[noRun,:,:] = outR[:,:nsave]\n",
    "    \n",
    "# save data\n",
    "\n",
    "filename = \"save_synthetic_data_v6_1.pkl\"\n",
    "\n",
    "\n",
    "metaInfo = 'batchsize: {}, nSamps0: {}, nSampsLate: {}, nupdate0: {}, nupdate_late: {}, w_scale: {}, runs: {}\\\n",
    "            '.format(batchsize,nSamps0, nSampsLate, nupdate0, nupdate_late, w_scale, runs)\n",
    "\n",
    "trueparams = [trueK,trueX0,trueDockP,trueRibbonLambda,dockMax,ribbonMax, truerho, truescale]\n",
    "\n",
    "dict_data = dict({'hypers': hypersSave, 'samples': outRSave, 'metaInfo': metaInfo, \n",
    "                  'trueparams':trueparams, 'truedata':data})\n",
    "with open(filename, \"wb\") as f:\n",
    "    pickle.dump(dict_data, f)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
